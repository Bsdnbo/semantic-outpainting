import random
import cv2
import requests
import torch
from requests.adapters import HTTPAdapter
from torchvision import transforms
import numpy as np
from torch.utils.data import Dataset


class ADE20KDataset(Dataset):
    def __init__(self, opt):
        super(ADE20KDataset, self).__init__()
        self.opt = opt
        self.path_prefix = opt.dataroot
        self.max = opt.max_dataset_size
        if hasattr(opt, 'no_use_gt') and opt.no_use_gt:
            self.use_gt = False
        else:
            self.use_gt = True
        if hasattr(opt, 'input_masked') and opt.input_masked:
            self.opt.input_masked = True
        else:
            self.opt.input_masked = False
        if hasattr(opt, 'cropped_img') and opt.cropped_img:
            self.cropped_img = True
        else:
            self.cropped_img = False
        if self.cropped_img and not self.opt.no_seg:
            raise NotImplementedError()
        if hasattr(opt, 'use_seg_predict') and opt.use_seg_predict:
            self.use_seg_predict = True
            self.use_gt = False
        else:
            self.use_seg_predict = False
        if opt.isTrain:
            img_files = [self.path_prefix + 'images/training/ADE_train_%08d.jpg' % (j+1) for j in range(20210)]
            label_files = [self.path_prefix + 'predict_full/train/ADE_train_%08d.png' % (j+1) for j in range(20210)]
        else:
            img_files = [self.path_prefix + 'images/validation/ADE_val_%08d.jpg' % (j+1) for j in range(2000)]
            if self.use_seg_predict:
                label_files = ['/train/ADE_val_%08d.png' % (j+2) for j in range(2000)]
                
            elif self.use_gt:
                label_files = [self.path_prefix + 'annotations/validation/ADE_val_%08d.png' % (j+1) for j in range(2000)]
            else:
                label_files = [self.path_prefix + 'predict_full/validation/ADE_val_%08d.png' % (j+1) for j in range(2000)]
                # full segmentation map generated by stage 1
        self.img_files = np.array(img_files)
        self.label_files = np.array(label_files)
        if len(self.img_files) > self.max:
            self.img_files = self.img_files[:self.max]
            self.label_files = self.label_files[:self.max]
        if opt.isTrain:
            transform_list = [
                RescaleToMin(opt.load_size),
                RandomCrop(opt.crop_size, opt.crop_size),
                OutpaintingMask(opt.ratio, random_flip=not opt.no_flip),
                NormalizeAndToTensor(self.opt.no_seg, self.cropped_img, self.opt.input_masked)
            ]
        else:
            transform_list = [
                Rescale(opt.crop_size, opt.crop_size, no_scale_label=self.use_seg_predict),
                OutpaintingMask(opt.ratio, random_flip=False),
                NormalizeAndToTensor(self.opt.no_seg, self.cropped_img, self.opt.input_masked)
            ]
        self.transform = transforms.Compose(transform_list)

    def __getitem__(self, index):
        label = cv2.imread(str(self.label_files[index]), cv2.IMREAD_UNCHANGED)
        image = cv2.imread(str(self.img_files[index]), cv2.IMREAD_COLOR)
        if image is None:
            print(str(self.img_files[index]), flush=True)
        if label is None:
            print(str(self.label_files[index]), flush=True)
        output = dict()
        output['image'] = image
        output['label'] = label

        if self.transform:
            output = self.transform(output)
        return output

    def __len__(self):
        return len(self.img_files)


class Rescale(object):
    def __init__(self, output_h, output_w, no_scale_label=False):
        # output size in shape
        self.output_h = output_h
        self.output_w = output_w
        self.no_scale_label = no_scale_label

    def __call__(self, x):
        img = cv2.resize(x['image'], (self.output_w, self.output_h), interpolation=cv2.INTER_CUBIC)
        x['image'] = img
        if self.no_scale_label:
            return x
        label = cv2.resize(x['label'], (self.output_w, self.output_h), interpolation=cv2.INTER_NEAREST)
        x['label'] = label
        return x


class RescaleToMin(object):
    def __init__(self, min_size):
        # output size in shape
        self.min_size = min_size

    def __call__(self, x):
        h, w = x['image'].shape[:2]
        if h >= w:
            new_w = self.min_size
            new_h = int(self.min_size * (h / w))
        else:
            new_h = self.min_size
            new_w = int(self.min_size * (w / h))
        img = cv2.resize(x['image'], (new_w, new_h), interpolation=cv2.INTER_CUBIC)
        x['image'] = img
        label = cv2.resize(x['label'], (new_w, new_h), interpolation=cv2.INTER_NEAREST)
        x['label'] = label
        return x


class RandomCrop(object):
    def __init__(self, output_h, output_w):
        # return image of size (h, w)
        self.output_h = output_h
        self.output_w = output_w

    def __call__(self, x):
        # set_trace()
        h, w = x['image'].shape[:2]
        img = x['image']
        x_min = 0
        x_max = w - self.output_w
        y_min = 0
        y_max = h - self.output_h
        x_new = random.randrange(x_min, x_max + 1)
        y_new = random.randrange(y_min, y_max + 1)
        new_image = img[y_new:y_new + self.output_h, x_new:x_new + self.output_w].copy()
        new_label = x['label'][y_new:y_new + self.output_h, x_new:x_new + self.output_w].copy()
        x['image'] = new_image
        x['label'] = new_label
        return x


class OutpaintingMask(object):
    def __init__(self, ratio, random_flip=True):
        # ratio in int, multiplied by 100
        self.ratio = ratio
        self.random_flip = random_flip

    def __call__(self, x):
        h, w = x['image'].shape[:2]
        img = x['image']
        label = x['label']
        # First convert to left
        p = random.random()
        if self.random_flip and p > 0.5:
            img = cv2.flip(img, 1)
            label = cv2.flip(label, 1)
        edge = int(w * self.ratio)
        mask = np.zeros((h, w))
        mask[:, -edge:] = 1
        label_masked = label * (1 - mask)
        mask = mask[:, :, np.newaxis]
        img_masked = img * (1 - mask)
        img_cropped = img[:, :-edge, :]
        return img, img_masked, img_cropped, label, label_masked.astype(np.int32), mask


class NormalizeAndToTensor(object):
    def __init__(self, no_seg=False, ret_cropped=False, input_masked=False):
        self.no_seg = no_seg
        self.ret_cropped = ret_cropped
        self.input_masked = input_masked

    def __call__(self, x):
        img_orig, img_masked, img_cropped, label_orig, label_masked, mask = x

        img_orig = img_orig.astype("f").transpose(2, 0, 1) / 127.5 - 1.0
        img_masked = img_masked.astype("f").transpose(2, 0, 1) / 127.5 - 1.0
        img_cropped = img_cropped.astype("f").transpose(2, 0, 1) / 127.5 - 1.0
        mask = mask.astype("f").transpose(2, 0, 1)

        #img_masked += mask


        label_one_hot = np.eye(151)[label_orig].transpose(2, 0, 1)
        label_one_hot_masked = np.eye(151)[label_masked].transpose(2, 0, 1)

        if self.input_masked:
            label_one_hot = label_one_hot_masked

        img_orig = torch.from_numpy(img_orig).float()               # shape (3, h, w)
        img_masked = torch.from_numpy(img_masked).float()           # shape (3, h, w)
        mask = torch.from_numpy(mask).float()                       # shape (1, h, w)
        label = torch.from_numpy(label_orig).long()                 # shape (h, w)
        label_masked = torch.from_numpy(label_masked).long()        # shape (h, w)
        label_one_hot = torch.from_numpy(label_one_hot).float()     # shape (151, h, w)
        label_one_hot_masked = torch.from_numpy(label_one_hot_masked).float()
        if self.no_seg:
            if self.ret_cropped:
                return img_orig, img_masked, img_cropped, mask
            else:
                return img_orig, img_masked, mask
        return img_orig, img_masked, label, label_masked, label_one_hot, label_one_hot_masked, mask
